{"cells":[{"cell_type":"markdown","metadata":{"id":"qYnJJYUxbdua"},"source":["# SteganoGAN in Keras\n","This notebook contains code attempting to reimplement SteganoGAN in Keras, for the purpose of better understanding (and scrutinizing) it.\n","\n","*Based on https://github.com/DAI-Lab/SteganoGAN/tree/master/steganogan*"]},{"cell_type":"markdown","metadata":{"id":"OTRQl5_KUxUA"},"source":["### Modules"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"QbnEM8Oubduh"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-21 19:17:39.572479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","import sys\n","sys.path.append(\"..\")\n","\n","import tensorflow as tf\n","from keras.optimizers import Adam\n","from keras.losses import BinaryCrossentropy\n","\n","from models import (\n","  steganogan_encoder_residual_model,\n","  steganogan_decoder_basic_model,\n","  steganogan_critic_model\n",")\n","from keras_steganogan_critic import KerasSteganoGAN"]},{"cell_type":"markdown","metadata":{},"source":["### Constants"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Image dimensions\n","IMAGE_HEIGHT = 128\n","IMAGE_WIDTH = 128\n","IMAGE_CHANNELS = 3\n","\n","IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n","MESSAGE_DEPTH = 2\n","BATCH_SIZE = 4\n","MODEL_PATH = '../pretrained_models/steganoGAN_residual_critic.keras'"]},{"cell_type":"markdown","metadata":{},"source":["----"]},{"cell_type":"markdown","metadata":{},"source":["### Build model for future train"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["encoder = steganogan_encoder_residual_model(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS, MESSAGE_DEPTH)\n","decoder = steganogan_decoder_basic_model(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS, MESSAGE_DEPTH)\n","critic = steganogan_critic_model(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n","\n","steganoGAN = KerasSteganoGAN(\n","  encoder=encoder,\n","  decoder=decoder,\n","  critic=critic,\n","  image_shape=IMAGE_SHAPE,\n","  data_depth=MESSAGE_DEPTH,\n","  model_path=MODEL_PATH\n",")\n","\n","steganoGAN.compile(\n","  encoder_optimizer = Adam(learning_rate=1e-4, beta_1=0.5),\n","  decoder_optimizer = Adam(learning_rate=1e-4, beta_1=0.5),\n","  critic_optimizer = Adam(learning_rate=1e-4, beta_1=0.5),\n","  loss_fn = BinaryCrossentropy(from_logits=False)\n",")\n","\n","#steganoGAN.models_summary()\n","#steganoGAN.summary()"]},{"cell_type":"markdown","metadata":{},"source":["### Download div2k dataset and complete it with random message dataset of {0, 1}"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 800 files.\n","Found 100 files.\n"]}],"source":["train_dir = '/Users/dmitryhoma/Projects/phd_dissertation/state_2/SteganoGAN/research/data/div2k/train'\n","val_dir = '/Users/dmitryhoma/Projects/phd_dissertation/state_2/SteganoGAN/research/data/div2k/val'\n","\n","train_image_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_dir, \n","    label_mode=None, \n","    color_mode='rgb',\n","    batch_size=BATCH_SIZE,\n","    seed=123,\n","    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","    shuffle=True\n",")\n","\n","val_image_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","    val_dir, \n","    label_mode=None, \n","    color_mode='rgb',\n","    batch_size=BATCH_SIZE,\n","    seed=123,\n","    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n","    shuffle=True\n",")\n","\n","def normalize_img(img):\n","    return (img / 127.5) - 1\n","\n","train_image_ds = train_image_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","val_image_ds = val_image_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","def create_message_tensor_for_training(batch_size, width, height, data_depth):\n","    message = tf.random.uniform([batch_size, width, height, data_depth], 0, 2, dtype=tf.int32)\n","    message = tf.cast(message, tf.float32)\n","    return message\n","\n","def create_message_dataset(batch_size, num_batches, width, height, data_depth):\n","    message_tensors = [create_message_tensor_for_training(batch_size, width, height, data_depth) for _ in range(num_batches)]\n","    return tf.data.Dataset.from_tensor_slices(tf.concat(message_tensors, axis=0)).batch(batch_size)\n","\n","train_message_ds = create_message_dataset(BATCH_SIZE, len(train_image_ds), IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH)\n","val_message_ds = create_message_dataset(BATCH_SIZE, len(val_image_ds), IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH)\n","\n","train_ds = tf.data.Dataset.zip((train_image_ds, train_message_ds)).prefetch(buffer_size=tf.data.AUTOTUNE)\n","val_ds = tf.data.Dataset.zip((val_image_ds, val_message_ds)).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -9.3637e-04 - decoding_loss: 0.7642 - encoder_decoder_total_loss: 1.0834 - psnr: 5.9730 - realism_loss: 7.2754e-05 - similarity_loss: 0.3191 - ssim: 0.2333 - val_bpp: 2.0000 - val_critic_loss: -0.0038 - val_decoding_loss: 0.6376 - val_encoder_decoder_total_loss: 0.6868 - val_psnr: 13.1818 - val_realism_loss: -3.1403e-04 - val_similarity_loss: 0.0496 - val_ssim: 0.4906\n","Epoch 2/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0081 - decoding_loss: 0.5248 - encoder_decoder_total_loss: 0.6034 - psnr: 11.2024 - realism_loss: 1.2444e-05 - similarity_loss: 0.0786 - ssim: 0.4121 - val_bpp: 2.0000 - val_critic_loss: -0.0189 - val_decoding_loss: 0.3325 - val_encoder_decoder_total_loss: 0.4043 - val_psnr: 11.2225 - val_realism_loss: -0.0057 - val_similarity_loss: 0.0775 - val_ssim: 0.3824\n","Epoch 3/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0245 - decoding_loss: 0.2340 - encoder_decoder_total_loss: 0.2874 - psnr: 11.9829 - realism_loss: -0.0117 - similarity_loss: 0.0651 - ssim: 0.4004 - val_bpp: 2.0000 - val_critic_loss: -0.0391 - val_decoding_loss: 0.1378 - val_encoder_decoder_total_loss: 0.1763 - val_psnr: 12.0832 - val_realism_loss: -0.0258 - val_similarity_loss: 0.0643 - val_ssim: 0.4087\n","Epoch 4/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0422 - decoding_loss: 0.1133 - encoder_decoder_total_loss: 0.1358 - psnr: 12.9269 - realism_loss: -0.0300 - similarity_loss: 0.0525 - ssim: 0.4386 - val_bpp: 2.0000 - val_critic_loss: -0.0493 - val_decoding_loss: 0.0780 - val_encoder_decoder_total_loss: 0.0940 - val_psnr: 13.0092 - val_realism_loss: -0.0361 - val_similarity_loss: 0.0521 - val_ssim: 0.4577\n","Epoch 5/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0497 - decoding_loss: 0.0779 - encoder_decoder_total_loss: 0.0822 - psnr: 13.6434 - realism_loss: -0.0404 - similarity_loss: 0.0447 - ssim: 0.4775 - val_bpp: 2.0000 - val_critic_loss: -0.0559 - val_decoding_loss: 0.0590 - val_encoder_decoder_total_loss: 0.0617 - val_psnr: 13.7471 - val_realism_loss: -0.0414 - val_similarity_loss: 0.0441 - val_ssim: 0.4994\n","Epoch 6/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0568 - decoding_loss: 0.0637 - encoder_decoder_total_loss: 0.0607 - psnr: 14.1964 - realism_loss: -0.0426 - similarity_loss: 0.0396 - ssim: 0.5065 - val_bpp: 2.0000 - val_critic_loss: -0.0648 - val_decoding_loss: 0.0490 - val_encoder_decoder_total_loss: 0.0511 - val_psnr: 14.0722 - val_realism_loss: -0.0386 - val_similarity_loss: 0.0407 - val_ssim: 0.5156\n","Epoch 7/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0634 - decoding_loss: 0.0549 - encoder_decoder_total_loss: 0.0506 - psnr: 14.5933 - realism_loss: -0.0406 - similarity_loss: 0.0362 - ssim: 0.5253 - val_bpp: 2.0000 - val_critic_loss: -0.0663 - val_decoding_loss: 0.0466 - val_encoder_decoder_total_loss: 0.0426 - val_psnr: 14.8459 - val_realism_loss: -0.0386 - val_similarity_loss: 0.0345 - val_ssim: 0.5516\n","Epoch 8/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0659 - decoding_loss: 0.0511 - encoder_decoder_total_loss: 0.0449 - psnr: 15.0122 - realism_loss: -0.0392 - similarity_loss: 0.0330 - ssim: 0.5471 - val_bpp: 2.0000 - val_critic_loss: -0.0689 - val_decoding_loss: 0.0433 - val_encoder_decoder_total_loss: 0.0407 - val_psnr: 15.1384 - val_realism_loss: -0.0347 - val_similarity_loss: 0.0322 - val_ssim: 0.5688\n","Epoch 9/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0693 - decoding_loss: 0.0508 - encoder_decoder_total_loss: 0.0479 - psnr: 15.3691 - realism_loss: -0.0335 - similarity_loss: 0.0306 - ssim: 0.5692 - val_bpp: 2.0000 - val_critic_loss: -0.0781 - val_decoding_loss: 0.0418 - val_encoder_decoder_total_loss: 0.0505 - val_psnr: 15.4629 - val_realism_loss: -0.0211 - val_similarity_loss: 0.0298 - val_ssim: 0.5907\n","Epoch 10/10\n","\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 1s/step - bpp: 2.0000 - critic_loss: -0.0803 - decoding_loss: 0.0529 - encoder_decoder_total_loss: 0.0653 - psnr: 15.8256 - realism_loss: -0.0153 - similarity_loss: 0.0277 - ssim: 0.5945 - val_bpp: 2.0000 - val_critic_loss: -0.0981 - val_decoding_loss: 0.0445 - val_encoder_decoder_total_loss: 0.0866 - val_psnr: 15.7778 - val_realism_loss: 0.0144 - val_similarity_loss: 0.0277 - val_ssim: 0.6112\n"]}],"source":["steganoGAN.build([(1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), (1, IMAGE_HEIGHT, IMAGE_WIDTH, MESSAGE_DEPTH)])\n","steganoGAN.fit(train_ds, epochs=10, validation_data=val_ds)\n","steganoGAN.save(MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"steganogan_keras.ipynb","provenance":[{"file_id":"https://github.com/jnickg/steganet/blob/main/steganogan_keras.ipynb","timestamp":1710610773710}]},"kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
